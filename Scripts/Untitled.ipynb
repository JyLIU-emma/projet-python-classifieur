{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, HashingVectorizer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from pre_traitement import load_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**train**: label: positif, nombre: 4\n",
      "**train**: label: negatif, nombre: 4\n",
      " Le nombre de [train] au total: 8\n",
      "\n",
      "**test**: label: positif, nombre: 4\n",
      "**test**: label: negatif, nombre: 8\n",
      " Le nombre de [test] au total: 12\n",
      "\n",
      "['Hmm … reste la croisière 2010 suis En économisant maintenant Je naviguerai vous …', 'Se balançant mon petit neveu un merveilleux moment', \"Aww that' a bummer … continuez bon combat …\", 'Lisez blog incroyable sujet vin de nourriture', \"Est-ce les jeux à dos un but C' dommage nous perdu encore l' amusement Heure sommeil puis vendredi\", \"C' vendredi … pas pay-day\", \"Itunes lira mes données d' exécution ne peux plus télécharger les prochaines semaines suppose je l' réglé …\", \"Je dirais Tous hôtels j' eu des lits vraiment doux Ça fait retour hu\"] ['positif', 'positif', 'positif', 'positif', 'negatif', 'negatif', 'negatif', 'negatif'] ['Enfin la maison … va changer vêtements se diriger vers salon coiffure … optimiste ce soir', 'Une autre semaine commence', \"J' dans groupe fois\", \"Essayant terminer bonbons j' eu mon anniversaire …\", \"O merde Je l' oublié … est jour pères J' toujours dates mélangées\", 'Le travail rend douloureux', \"déteste vie Pourquoi l' école existe-t-elle ma vie 3 jours…\", 'Est excité fête plage aussi très malade', \"Bonjour J' espère tout monde a passé super weekend Pas prêt retourner travail je suppose nous n' pas choix\", \"C' génial Mais fonctionne lentement mon ordinateur oldish\", 'A délimité 2 présidents morts que monde sur bite Drake Le hip hop vraiment mort', 'Donc le nettoyage Mais propre devons'] ['positif', 'positif', 'positif', 'positif', 'negatif', 'negatif', 'negatif', 'negatif', 'negatif', 'negatif', 'negatif', 'negatif']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-016d4b5573f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_datasets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# I. Extraction des features avec TF-IDF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtfidf_vectorizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mX_train_tfidf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfidf_vectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "X_train, y_train, X_test, y_test = load_datasets()\n",
    "\n",
    "# I. Extraction des features avec TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "words = tfidf_vectorizer.get_feature_names()\n",
    "print(\"*\"*15 + \"Traitement des features avec TF-IDF\" + \"*\"*15)\n",
    "\n",
    "# 1. naive bayes \n",
    "\n",
    "# Pipeline\n",
    "text_clf = Pipeline([('vect',TfidfVectorizer()),('clf',MultinomialNB())])\n",
    "text_clf.fit(X_train, y_train)\n",
    "\n",
    "predicted = text_clf.predict(X_test)\n",
    "print(\"Naive Bayes : MultinomialNB()\")\n",
    "print(classification_report(predicted, y_test))\n",
    "\n",
    "# 2. Logistic Regression\n",
    "text_clf_lr = Pipeline([('vect',TfidfVectorizer()),('clf',LogisticRegression())])\n",
    "text_clf_lr.fit(X_train, y_train)\n",
    "\n",
    "predicted_lr = text_clf_lr.predict(X_test)\n",
    "print(\"Logistic Regression : LogisticRegression()\")\n",
    "print(classification_report(predicted_lr, y_test))\n",
    "\n",
    "\n",
    "# 3. SVM \n",
    "text_clf_svm = Pipeline([('vect',TfidfVectorizer()),('clf',SGDClassifier(loss=\"hinge\", penalty=\"l2\"))])\n",
    "text_clf_svm.fit(X_train, y_train)\n",
    "\n",
    "predicted_svm = text_clf_svm.predict(X_test)\n",
    "print(\"SVM : SGDClassifier()\")\n",
    "print(classification_report(predicted_svm, y_test))\n",
    "\n",
    "# 4. Decision Tree\n",
    "text_clf_dt = Pipeline([('vect',CountVectorizer()),('clf',DecisionTreeClassifier())])\n",
    "text_clf_dt.fit(X_train, y_train)\n",
    "\n",
    "predicted_dt = text_clf_dt.predict(X_test)\n",
    "print(\"Decision Tree : DecisionTreeClassifier()\")\n",
    "print(classification_report(predicted_dt, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (sklearn)",
   "language": "python",
   "name": "sklearn-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
